package cn.oldensheepdog.performance;

/**
 * https://www.guru99.com/performance-testing.html
 * https://blog.51cto.com/u_15127575/3267836
 * https://zhuanlan.zhihu.com/p/36880929
 *
 * the speed, response time, stability, reliability, scalability and resource usage of a software application under particular workload.
 * Types of Performance Testing
 *
 * 性能基线的含义就是在可控的标准化的环境下，通过测试工具采集和人工分析后得出的有参考价值的指标数据。
 * 1.为容量规划确定系统和应用程序的极限；
 * 2.为配置测试的参数和配置选项提供参考依据；
 * 3.为验收测试确定系统是否具备自己所宣称的能力；
 * 4.为性能基线的建立提供长期的数据统计来源以及比较基准。
 *
 * 并发数： 系统同时处理的事务数
 * 吞吐量：一段时间内应用系统处理用户的请求数（以下介绍指单位时间内，也可以理解为吞吐率）
 * 并发用户数：指同一时间点对业务功能同时操作的用户数
 * 平均并发用户数的计算：C=nL / T
 * 其中C是平均的并发用户数，n是平均每天访问用户数，L是一天内用户从登录到退出的平均时间（操作平均时间），T是考察时间长度（一天内多长时间有用户使用系统）
 * 吞吐量计算：当没有遇到性能瓶颈的时候，吞吐量与虚拟用户数之间存在一定的联系，可以采用以下公式计算：F=VU * R / T其中F为吞吐量，VU表示虚拟用户个数，
 * R表示每个虚拟用户发出的请求数，T表示性能测试所用的时间，其实通过这个公式就能看出吞吐量与并发用户数之间的关系了（这里的VU就是我们用工具模拟的并发用户数）。
 *
 *
 * 由于目前的性能需求往往都是并发+响应时间这样的描述，并不能对应的了QPS值，无法指导计算资源评估，为了将性能基线通俗化，需要进行一下换算。
 * 考虑到事务复杂度不一，为了便于换算，统一预估单事务平均包含10个请求，单事务响应时间为3秒。基于单机器4核8G，QPS值为650~1000之间，
 * 依照换算公式“并发=QPS/单事务请求数*事务响应时间”，支撑并发量为195~300之间。故通俗化的基线指标为，单台4核8Gweb服务器，支持用户并发195~300间。
 * 按此，一个需要满足1000并发量要求的系统，大致需要4台4核8Gweb服务器。
 *
 * Load Testing: checks the application’s ability to perform under anticipated user loads.
 * The objective is to identify performance bottlenecks before the software application goes live.
 * 负载测试： 根据以往线上系统的用户流量情况，预期用户负载下确定系统瓶颈，满足上线要求
 *
 * Stress testing – involves testing an application under extreme workloads to see how it handles high traffic or data processing.
 * The objective is to identify the breaking point of an application.
 * 压力测试： 在极端高负载下测试应用程序，了解它如何处理高流量，目的是找出应用程序的断点
 *
 * Endurance testing – is done to make sure the software can handle the expected load over a long period of time.
 * 耐力测试，确定应用程序能长时间承受期望的负载
 *
 * Spike testing – tests the software’s reaction to sudden large spikes in the load generated by users.
 * 峰值测试，测试软件对用户负载突然出现大峰值的反应
 *
 * Volume testing – Under Volume Testing large no. of. Data is populated in a database and the overall software system’s behavior is monitored.
 * The objective is to check software application’s performance under varying database volumes.
 * 容量测试，确定系统可处理同时在线的最大用户数，大数据量
 *
 * 设计一个场景，总共10000用户，20%在登录，50%在交易，30%在查看
 *
 * 性能测试基本概念：
 * https://cloud.tencent.com/developer/article/1629643
 *
 * 性能测试包含了哪些测试类型？
 * 负载测试（Load Testing）：测试软件系统是否达到需求文档设计的目标，譬如软件在一定时期内，保持配置不变的情况下，最大支持多少并发用户数，软件请求出错率等；
 * 压力测试（Stress Testing）：压力测试也称为强度测试，主要测试硬件系统是否达到需求文档设计的性能目标，譬如在一定时期内，系统的CPU利用率，
 * 内存使用率，磁盘I/O吞吐率，网络吞吐量等，压力测试和负载测试最大的差别在于测试目的不同；
 * 容量测试（Volume Testing）：确定系统最大承受量，譬如系统最大用户数，最大存储量，最多处理的数据流量等；
 * 并发测试（Concurrent Testing）: 测试多用户并发访问同一个应用、模块、数据时是否产生隐藏的并发问题；
 * 基准测试 （BenchmarkTesting）:比较新的或未知测试对象与已知参照标准（如现有软件或评测标准）的性能；
 *
 * 简述性能测试流程
 * 1.分析性能需求。挑选用户使用最频繁的场景来测试，比如：登陆，搜索，下单等等。确定性能指标，比如：事务通过率为100%，TOP99%是5秒，最大并发用户为1000人，CPU和内存的使用率在70%以下
 * 99th PCT
 * 2.制定性能测试计划，明确测试时间(通常在功能稳定后，如第一轮测试后进行)和测试环境和测试工具
 * 3.编写测试用例
 * 4.搭建测试环境，准备好测试数据
 * 5.编写性能测试脚本
 * 6.性能测试脚本调优。设置检查点、参数化、关联、集合点、事务，调整思考时间，删除冗余脚本
 * 7.设计测试场景，运行测试脚本，监控服务器，
 * 8.分析测试结果，收集相关的日志提单给开发
 * 9.回归性能测试
 * 10.编写测试报告
 * 如何确定系统最大负载？
 * 通过负载测试，不断增加用户数，随着用户数的增加，各项性能指标也会相应产生变化，当出现了性能拐点，比如，当用户数达到某个数量级时，响应时间突然增长，
 * 那么这个拐点处对应的用户数就是系统能承载的最大用户数。
 *
 * 你们系统哪些地方(哪些功能)做了性能测试？
 *
 * 选用了用户使用最频繁的功能来做测试，比如：登陆，搜索，签署合同，提交订单，
 *
 * 你们的并发用户数是怎么确定的？
 * 1）会先上线一段时间，根据收集到的用户访问数据进行预估
 * 2）根据需求来确定（使用高峰时间段，注册用户数，单次响应时间等
 *
 * 性能测试在什么环境执行？
 * 参考答案：我们会搭建一套独立的性能测试环境进行测试
 *
 * 性能测试什么时间执行？
 * 基准测试：功能测试之后，系统比较稳定的时候再做。
 * 负载测试：夜深人静，系统没人用的时候
 *
 * 怎么分析性能测试结果？
 *
 * 首先查看事务通过率，然后分析其他性能指标，比如，确认响应时间，事务通过率，CPU等指标是否满足需求；如果测试结果不可信，要分析异常的原因，修改后重新测试
 * TPS, throughput， Request Time RT响应时间, Error Rate, CPU, Memory，IO，Disk
 * think_time的作用是什么？
 * 模拟真实生产用户操作，考察对服务器所造成的影响。
 *
 * 在确定性能测试结果可信后，如果发现以下问题，按下面提供的思路来定位问题
 * 问题一：响应时间不达标
 * 查看事务所消耗的时间主要在网络传输还是服务器，如果是网络，就结合Throughput(网络吞吐量)图，计算带宽是否存在瓶颈，如果存在瓶颈，就要考虑增加带宽，
 * 或对数据的传输进行压缩处理；如果不存在瓶颈，那么，可能是网路不稳定导致。如果主要时间是消耗在服务器上，就要分别查看web服务器和数据库服务器的CPU，
 * 内存的使用率是否过高，因为过高的CPU，内存必定会造成响应时间过长，如果是web服务器的问题，就把web服务器对应上对应的用户操作日志取下来，发给开发定位；
 * 如果是数据库的问题，就把数据库服务器对应上对应的日志取下来，发给开发定位。
 *
 * 问题二：服务器CPU指标异常
 * 分析思路：就把web服务器对应上对应的用户操作日志取下来，发给开发定位。
 * 问题三：数据库CPU指标异常
 * 分析思路：把数据库服务器对应上对应的日志取下来，发给开发定位
 * 问题四：内存泄漏
 * 分析思路：把内存的heap数据取出来，分析是哪个对象消耗内存最多，然后发给开发定位。
 * https://blog.csdn.net/weixin_38004638/article/details/106048793
 * jps  查看所有java进程，输出JVM中运行的进程状态信息
 * top   查看cpu占用高进程
 * 找出该进程中最耗费CPU的Java线程
 * top -Hp pid  或者  ps -Lfp pid
 * printf %x 21742 -> 54ee
 * jstack 21711 | grep 54ee
 *
 * jstack统计线程数
 * jstat监控jvm内存，查看full gc频率
 * jmap查看某个进程的对象占用对象最大情况
 *
 * 问题五：程序在单用户场景下运行成功，多用户运行则失败，提示连不上服务器。
 * 原因：程序可能是单线程处理机制
 *
 * 如何识别系统瓶颈？
 * 从TPS指标分析，TPS即系统单位时间内处理事务的数量。观察当前随着用户数的增长期系统每秒可处理的事务数是否也会增长
 * 如何判断系统的性能是变好了还是变坏了
 * 通过基准测试对比性能指标
 *
 * 你们的性能测试需求哪里来？
 * 1：客户提供需求
 * 2：运维提供需求
 * 3：开发提供需求
 * 如何实现200用户的并发？
 * 在脚本对应的请求后添加集合点
 * 什么情况下要做关联，关联是怎么做的？
 * 当脚本的上下文有联系，就用关联。
 * 比如登录的token关联，增删改查主键id关联
 * 有验证码的功能，怎么做性能测试？
 * 1、将验证码暂时屏蔽，完成性能测试后，再恢复
 * 2、使用万能的验证码
 *
 * 你们性能测试做的是前台还是后台？
 * BS项目：测试的是后台服务器的性能和浏览器端性能；
 * APP项目：手机端和服务器端的性能都做
 *
 * 如何脚本增强？1、做参数化 2、做关联 3、添加事务 4、添加断言 5、添加集合点 6、添加思考时间
 *
 *
 * 阈值 threshold
 * */

public class Performance {
}
